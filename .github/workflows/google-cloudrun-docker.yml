# This workflow builds and deploys a Go application to Google Cloud Run.
#
# To use this workflow, you must set up the following secrets in your GitHub repository:
#
# - WIF_PROVIDER: The full identifier of the Workload Identity Provider.
#   (e.g., projects/123456789/locations/global/workloadIdentityPools/github/providers/my-repo)
#
# - WIF_SERVICE_ACCOUNT: The email address of the service account to use.
#   (e.g., sbcwaste@sbcwaste.iam.gserviceaccount.com)
#
# Note: The `scripts/deploy-githubactions.sh` script can be used to set up the
#       necessary Google Cloud resources and will output the values for
#       WIF_PROVIDER and WIF_SERVICE_ACCOUNT.

name: Build and Deploy to Google Cloud Run

on:
  workflow_dispatch:
    inputs:
      CACHE_EXPIRY_SECONDS:
        description: 'Cache expiry in seconds'
        required: true
        default: '259200'
  push:
    branches:
      - main
      - dev
  pull_request:
    branches:
      - main
      - dev

permissions:
  contents: read
  id-token: write

env:
  PROJECT_ID: sbcwaste
  GAR_LOCATION: europe-west1
  REPO: eu-docker-repo
  IMAGE: sbcwaste
  REGION: europe-west1

jobs:
  build:
    name: Build, Scan, and Push
    runs-on: ubuntu-latest
    outputs:
      image_name: ${{ steps.build-image.outputs.image_name }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get install -y jq

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Run tests
        run: go test ./...

      - name: Run Gosec Security Scanner
        uses: securego/gosec@master
        with:
          args: './src/...'

      - name: Build Docker image
        id: build-image
        run: |
          docker build -t ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}/${{ env.IMAGE }}:${{ github.sha }} .
          echo "image_name=${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}/${{ env.IMAGE }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Scan image for vulnerabilities
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.build-image.outputs.image_name }}
          format: 'table'
          exit-code: '1'
          ignore-unfixed: true
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'

      - name: Authenticate to Google Cloud
        if: github.event_name == 'push'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        if: github.event_name == 'push'
        uses: google-github-actions/setup-gcloud@v2

      - name: Display authenticated user
        if: github.event_name == 'push'
        run: gcloud auth list

      - name: Display authenticated user
        if: github.event_name == 'push'
        run: |
          ACCOUNT=$(gcloud config get-value account)
          echo "Authenticated user: ${ACCOUNT//@/ [at] }"

      - name: Enable Google Cloud services
        if: github.event_name == 'push'
        run: |
          gcloud services enable artifactregistry.googleapis.com
          gcloud services enable artifactanalysis.googleapis.com
          gcloud artifacts repositories set-scanning-config ${{ env.REPO }} \
            --location=${{ env.GAR_LOCATION }} \
            --project=${{ env.PROJECT_ID }} \
            --no-dry-run

      - name: Configure Docker
        if: github.event_name == 'push'
        run: gcloud auth configure-docker ${{ env.GAR_LOCATION }}-docker.pkg.dev -q

      - name: Push Docker image
        if: github.event_name == 'push'
        run: docker push ${{ steps.build-image.outputs.image_name }}

      - name: Check for vulnerabilities in Artifact Registry
        if: github.event_name == 'push'
        run: |
          # The image name is in the format: europe-west1-docker.pkg.dev/sbcwaste/eu-docker-repo/sbcwaste@sha256:digest
          # We need to extract the digest to form the console URL.
          IMAGE_DIGEST=$(echo "${{ steps.build-image.outputs.image_name }}" | cut -d'@' -f2)
          CONSOLE_URL="https://console.cloud.google.com/artifacts/images/${{ env.PROJECT_ID }}/${{ env.GAR_LOCATION }}/${{ env.REPO }}/${{ env.IMAGE }};version=${IMAGE_DIGEST}?project=${{ env.PROJECT_ID }}"

          echo "Vulnerability scan running. View results at: ${CONSOLE_URL}"
          echo "Waiting for scan to complete..."

          vuln_scan_status="PENDING"
          for i in {1..10}; do
            # The vulnerability scan can take a few minutes to complete.
            # We poll the status until it is finished.
            vuln_scan_status=$(gcloud artifacts docker images describe ${{ steps.build-image.outputs.image_name }} --format='value(discovery_summary.discovery.analysis_status)')
            if [ "$vuln_scan_status" == "FINISHED_SUCCESS" ]; then
              echo "Vulnerability scan completed successfully."
              break
            elif [ "$vuln_scan_status" == "FINISHED_FAILED" ] || [ "$vuln_scan_status" == "FINISHED_UNSUPPORTED" ]; then
              echo "Vulnerability scan finished with status: ${vuln_scan_status}"
              echo "View details at: ${CONSOLE_URL}"
              exit 1
            fi
            echo "Attempt $i: Scan status is '${vuln_scan_status}'. Waiting 30 seconds..."
            sleep 30
          done

          if [ "$vuln_scan_status" != "FINISHED_SUCCESS" ]; then
            echo "Vulnerability scan did not complete in time. Final status: '${vuln_scan_status}'"
            echo "View details at: ${CONSOLE_URL}"
            exit 1
          fi

          # Check for high or critical severity vulnerabilities.
          # The `gcloud ... scan` command has been deprecated in favor of `gcloud artifacts vulnerability-scanning ...`
          # However, for simplicity and to avoid parsing large JSON, we'll check the discovery summary.
          # We will query for any vulnerability with a HIGH or CRITICAL severity.
          # The --format="value(vulnerability_summary.counts[?severity='CRITICAL' || severity='HIGH'].count)" command
          # will return the counts of high and critical vulnerabilities. If the sum is greater than 0, we fail.
          critical_count=$(gcloud artifacts docker images describe ${{ steps.build-image.outputs.image_name }} --format="value(vulnerability_summary.counts[?severity='CRITICAL'].count)" | awk '{s+=$1} END {print s}')
          high_count=$(gcloud artifacts docker images describe ${{ steps.build-image.outputs.image_name }} --format="value(vulnerability_summary.counts[?severity='HIGH'].count)" | awk '{s+=$1} END {print s}')

          total_vulns=$((critical_count + high_count))

          if [ "$total_vulns" -gt 0 ]; then
            echo "Found ${critical_count} CRITICAL and ${high_count} HIGH severity vulnerabilities."
            echo "Failing build. View details at: ${CONSOLE_URL}"
            exit 1
          else
            echo "No HIGH or CRITICAL vulnerabilities found."
          fi

  deploy:
    name: Deploy to Cloud Run
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - name: Set up deployment environment
        id: set-env
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "APP_ENV=prod" >> $GITHUB_ENV
            echo "SERVICE=sbcwaste-prod" >> $GITHUB_ENV
            echo "DOMAIN=sbcwaste.top" >> $GITHUB_ENV
          elif [ "${{ github.ref }}" == "refs/heads/dev" ]; then
            echo "APP_ENV=dev" >> $GITHUB_ENV
            echo "SERVICE=sbcwaste-dev" >> $GITHUB_ENV
            echo "DOMAIN=dev.sbcwaste.top" >> $GITHUB_ENV
          fi

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Deploy to Cloud Run
        uses: google-github-actions/deploy-cloudrun@v2
        with:
          service: ${{ env.SERVICE }}
          region: ${{ env.REGION }}
          image: ${{ needs.build.outputs.image_name }}
          env_vars: |
            APP_ENV=${{ env.APP_ENV }}
            PROJECT_ID=${{ env.PROJECT_ID }}
            CACHE_EXPIRY_SECONDS=${{ github.event.inputs.CACHE_EXPIRY_SECONDS || '259200' }}

      - name: Verify DNS
        run: |
          echo "Verifying DNS for ${{ env.DOMAIN }}..."
          for i in {1..10}; do
            cname=$(dig +short ${{ env.DOMAIN }} CNAME)
            if [ "$cname" == "ghs.googlehosted.com." ]; then
              echo "DNS verification successful."
              exit 0
            fi
            echo "Attempt $i: DNS not yet propagated. Waiting 30 seconds..."
            sleep 30
          done
          echo "DNS verification failed after several attempts."
          exit 1

      - name: Verify Application Health
        run: |
          echo "Verifying application health for https://${{ env.DOMAIN }}"
          # First, check the /health endpoint
          for i in {1..10}; do
            response_code=$(curl -s -o /dev/null -w "%{http_code}" "https://${{ env.DOMAIN }}/health")
            if [ "$response_code" == "200" ]; then
              body=$(curl -s "https://${{ env.DOMAIN }}/health")
              if echo "$body" | grep -q '{"status": "ok"}'; then
                echo "Health check successful on /health endpoint."
                break
              else
                echo "Attempt $i: /health endpoint is up, but response is not as expected. Waiting 30 seconds..."
              fi
            else
              echo "Attempt $i: /health endpoint not yet responding with 200 OK (Got $response_code). Waiting 30 seconds..."
            fi
            sleep 30
          done

          if [ $i -eq 10 ]; then
            echo "Health check on /health endpoint failed after several attempts."
            exit 1
          fi

          # Second, check the root path to ensure the app is serving static assets
          for i in {1..10}; do
            response_code=$(curl -s -o /dev/null -w "%{http_code}" "https://${{ env.DOMAIN }}/")
            if [ "$response_code" == "200" ]; then
              echo "Health check successful on root path."
              exit 0
            else
              echo "Attempt $i: Root path not yet responding with 200 OK (Got $response_code). Waiting 30 seconds..."
            fi
            sleep 30
          done

          echo "Health check on root path failed after several attempts."
          exit 1

  cleanup-images:
    name: Clean up old container images
    needs: deploy
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev')
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Clean up old images
        continue-on-error: true
        run: |
          echo "Identifying images to clean up in ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}"

          # Get the image digests for the currently deployed services.
          # The service might not exist, so we default to an empty string.
          prod_image=$(gcloud run services describe sbcwaste-prod --platform managed --region ${{ env.REGION }} --format 'value(template.containers.image)' 2>/dev/null) || prod_image=""
          dev_image=$(gcloud run services describe sbcwaste-dev --platform managed --region ${{ env.REGION }} --format 'value(template.containers.image)' 2>/dev/null) || dev_image=""

          echo "Currently deployed images:"
          echo "Prod: ${prod_image:-'not found'}"
          echo "Dev: ${dev_image:-'not found'}"

          # Get all image versions, sorted from newest to oldest.
          all_images_output=$(gcloud artifacts docker images list ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }} --sort-by=~CREATE_TIME --format="get(version)" 2>/dev/null) || all_images_output=""

          # If there are no images in the repo, we can exit successfully.
          if [ -z "$all_images_output" ]; then
            echo "No images found in repository. Nothing to do."
            exit 0
          fi

          # Filter for images of the current service. If grep finds nothing, it exits with 1,
          # so we add `|| true` to prevent the script from exiting.
          all_images=$(echo "$all_images_output" | grep "/${{ env.IMAGE }}@" || true)

          # If there are no images for this service, we can exit successfully.
          if [ -z "$all_images" ]; then
            echo "No images found for this service. Nothing to do."
            exit 0
          fi

          # Build a unique list of images to keep
          images_to_keep_list=()
          [ -n "$prod_image" ] && images_to_keep_list+=("$prod_image")
          [ -n "$dev_image" ] && images_to_keep_list+=("$dev_image")

          # Add the 5 most recent images to the keep list
          images_to_keep_list+=($(echo "$all_images" | head -n 5))

          # Create a unique, sorted list of images to keep
          unique_keep_list=$(printf "%s\n" "${images_to_keep_list[@]}" | sort -u)

          echo "The following images will be kept:"
          echo "$unique_keep_list"

          # Use `grep` to find images that are in all_images but not in unique_keep_list.
          # If grep finds no images to delete, it exits with 1, so we add `|| true`.
          delete_list=$(echo "$all_images" | grep -vFx -f <(echo "$unique_keep_list") || true)

          # Delete the images if the delete list is not empty
          if [ -n "$delete_list" ]; then
            echo "The following images will be deleted:"
            echo "$delete_list"
            echo "$delete_list" | xargs -r gcloud artifacts docker images delete --delete-tags -q
          else
            echo "No images to delete."
          fi