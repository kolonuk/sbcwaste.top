# This workflow builds and deploys a Go application to Google Cloud Run.
#
# To use this workflow, you must set up the following secrets in your GitHub repository:
#
# - WIF_PROVIDER: The full identifier of the Workload Identity Provider.
#   (e.g., projects/123456789/locations/global/workloadIdentityPools/github/providers/my-repo)
#
# - WIF_SERVICE_ACCOUNT: The email address of the service account to use.
#   (e.g., sbcwaste@sbcwaste.iam.gserviceaccount.com)
#
# Note: The `scripts/deploy-githubactions.sh` script can be used to set up the
#       necessary Google Cloud resources and will output the values for
#       WIF_PROVIDER and WIF_SERVICE_ACCOUNT.

name: Build and Deploy to Google Cloud Run

on:
  workflow_dispatch:
    inputs:
      CACHE_EXPIRY_SECONDS:
        description: 'Cache expiry in seconds'
        required: true
        default: '259200'
  push:
    branches:
      - main
      - dev
  pull_request:
    branches:
      - main
      - dev

permissions:
  contents: read
  id-token: write

env:
  PROJECT_ID: sbcwaste
  GAR_LOCATION: europe-west1
  REPO: eu-docker-repo
  IMAGE: sbcwaste
  REGION: europe-west1

jobs:
  build:
    name: Build, Scan, and Push
    runs-on: ubuntu-latest
    outputs:
      image_name: ${{ steps.build-image.outputs.image_name }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install jq
        run: sudo apt-get install -y jq

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'

      - name: Run tests
        run: go test ./src/...

      - name: Run Gosec Security Scanner
        uses: securego/gosec@master
        with:
          args: './src/...'

      - name: Build Docker image
        id: build-image
        run: |
          docker build -t ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}/${{ env.IMAGE }}:${{ github.sha }} .
          echo "image_name=${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}/${{ env.IMAGE }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Scan image for vulnerabilities
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.build-image.outputs.image_name }}
          format: 'table'
          exit-code: '1'
          ignore-unfixed: true
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH'

      - name: Authenticate to Google Cloud
        if: github.event_name == 'push'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        if: github.event_name == 'push'
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker
        if: github.event_name == 'push'
        run: gcloud auth configure-docker ${{ env.GAR_LOCATION }}-docker.pkg.dev -q

      - name: Push Docker image
        if: github.event_name == 'push'
        run: docker push ${{ steps.build-image.outputs.image_name }}

      - name: Check for vulnerabilities in Artifact Registry
        if: github.event_name == 'push'
        run: |
          IMAGE_WITH_TAG="${{ steps.build-image.outputs.image_name }}"
          IMAGE_URL_NO_TAG="${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}/${{ env.IMAGE }}"

          echo "Fetching image digest..."
          IMAGE_DIGEST_FULL=$(gcloud artifacts docker images describe ${IMAGE_WITH_TAG} --format='get(version)' --quiet)
          if [ -z "$IMAGE_DIGEST_FULL" ]; then
            echo "❌ Failed to get image digest for ${IMAGE_WITH_TAG}"
            exit 1
          fi
          echo "Image digest: ${IMAGE_DIGEST_FULL}"

          # The resource URL for the occurrence filter needs the digest, not the tag.
          RESOURCE_URL="https://${IMAGE_URL_NO_TAG}@${IMAGE_DIGEST_FULL}"

          # Correctly construct the URL for the vulnerability report
          CONSOLE_URL="https://console.cloud.google.com/artifacts/docker/${{ env.PROJECT_ID }}/${{ env.GAR_LOCATION }}/${{ env.REPO }}/${{ env.IMAGE }}/sha256:$(echo -n ${IMAGE_DIGEST_FULL} | sed 's/sha256://');tab=vulnerabilities?project=${{ env.PROJECT_ID }}"

          echo "Waiting for vulnerability scan to complete..."
          echo "View progress at: ${CONSOLE_URL}"

          # Poll for up to 5 minutes (30 attempts * 10 seconds)
          for i in {1..30}; do
            # Check for the existence of the vulnerability occurrence. If the scan is complete, the 'kind' will be 'VULNERABILITY'.
            scan_status=$(gcloud artifacts docker images list ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }} \
              --filter="package='${IMAGE_URL_NO_TAG}'" \
              --show-occurrences \
              --occurrence-filter="kind=\"VULNERABILITY\" AND resource_url=\"${RESOURCE_URL}\"" \
              --format="get(occurrences[0].kind)" --quiet)

            if [ "$scan_status" == "VULNERABILITY" ]; then
              echo -e "\n---"
              echo "✅ Vulnerability scan complete."
              break
            else
              echo -n "."
            fi

            if [ $i -eq 30 ]; then
              echo -e "\n---"
              echo "❌ Timed out waiting for vulnerability scan results after 5 minutes."
              echo "Please check the status manually at: ${CONSOLE_URL}"
              exit 1
            fi
            sleep 10
          done

          # Now that the scan is complete, get the full summary
          echo "Fetching vulnerability summary..."
          vuln_summary_json=$(gcloud artifacts docker images describe ${IMAGE_WITH_TAG} --format=json --quiet)

          if [ -z "$vuln_summary_json" ]; then
            echo "❌ Failed to fetch vulnerability summary."
            exit 1
          fi

          critical_count=$(echo "$vuln_summary_json" | jq -r '.vulnerability_summary.counts[] | select(.severity=="CRITICAL") | .count' | awk '{s+=$1} END {print s+0}')
          high_count=$(echo "$vuln_summary_json" | jq -r '.vulnerability_summary.counts[] | select(.severity=="HIGH") | .count' | awk '{s+=$1} END {print s+0}')
          medium_count=$(echo "$vuln_summary_json" | jq -r '.vulnerability_summary.counts[] | select(.severity=="MEDIUM") | .count' | awk '{s+=$1} END {print s+0}')
          low_count=$(echo "$vuln_summary_json" | jq -r '.vulnerability_summary.counts[] | select(.severity=="LOW") | .count' | awk '{s+=$1} END {print s+0}')

          echo "---"
          echo "Vulnerability Scan Summary:"
          echo "- CRITICAL: ${critical_count}"
          echo "- HIGH:     ${high_count}"
          echo "- MEDIUM:   ${medium_count}"
          echo "- LOW:      ${low_count}"
          echo "---"

          if [ "$critical_count" -gt 0 ] || [ "$high_count" -gt 0 ]; then
            echo "❌ Found ${critical_count} CRITICAL and ${high_count} HIGH severity vulnerabilities."
            echo "Failing build. View details at: ${CONSOLE_URL}"
            exit 1
          else
            echo "✅ No CRITICAL or HIGH severity vulnerabilities found."
          fi

  deploy:
    name: Deploy to Cloud Run
    needs: build
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - name: Set up deployment environment
        id: set-env
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "APP_ENV=prod" >> $GITHUB_ENV
            echo "SERVICE=sbcwaste-prod" >> $GITHUB_ENV
            echo "DOMAIN=sbcwaste.top" >> $GITHUB_ENV
          elif [ "${{ github.ref }}" == "refs/heads/dev" ]; then
            echo "APP_ENV=dev" >> $GITHUB_ENV
            echo "SERVICE=sbcwaste-dev" >> $GITHUB_ENV
            echo "DOMAIN=dev.sbcwaste.top" >> $GITHUB_ENV
          fi

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Deploy to Cloud Run
        uses: google-github-actions/deploy-cloudrun@v2
        with:
          service: ${{ env.SERVICE }}
          region: ${{ env.REGION }}
          image: ${{ needs.build.outputs.image_name }}
          env_vars: |
            APP_ENV=${{ env.APP_ENV }}
            PROJECT_ID=${{ env.PROJECT_ID }}
            CACHE_EXPIRY_SECONDS=${{ github.event.inputs.CACHE_EXPIRY_SECONDS || '259200' }}

      - name: Verify DNS
        run: |
          echo "Verifying DNS for ${{ env.DOMAIN }}..."
          for i in {1..10}; do
            cname=$(dig +short ${{ env.DOMAIN }} CNAME)
            if [ "$cname" == "ghs.googlehosted.com." ]; then
              echo "DNS verification successful."
              exit 0
            fi
            echo "Attempt $i: DNS not yet propagated. Waiting 30 seconds..."
            sleep 30
          done
          echo "DNS verification failed after several attempts."
          exit 1

      - name: Verify Application Health
        run: |
          echo "Verifying application health for https://${{ env.DOMAIN }}"
          # First, check the /health endpoint
          for i in {1..10}; do
            response_code=$(curl -s -o /dev/null -w "%{http_code}" "https://${{ env.DOMAIN }}/health")
            if [ "$response_code" == "200" ]; then
              body=$(curl -s "https://${{ env.DOMAIN }}/health")
              if echo "$body" | grep -q '{"status": "ok"}'; then
                echo "Health check successful on /health endpoint."
                break
              else
                echo "Attempt $i: /health endpoint is up, but response is not as expected. Waiting 30 seconds..."
              fi
            else
              echo "Attempt $i: /health endpoint not yet responding with 200 OK (Got $response_code). Waiting 30 seconds..."
            fi
            sleep 30
          done

          if [ $i -eq 10 ]; then
            echo "Health check on /health endpoint failed after several attempts."
            exit 1
          fi

          # Second, check the root path to ensure the app is serving static assets
          for i in {1..10}; do
            response_code=$(curl -s -o /dev/null -w "%{http_code}" "https://${{ env.DOMAIN }}/")
            if [ "$response_code" == "200" ]; then
              echo "Health check successful on root path."
              exit 0
            else
              echo "Attempt $i: Root path not yet responding with 200 OK (Got $response_code). Waiting 30 seconds..."
            fi
            sleep 30
          done

          echo "Health check on root path failed after several attempts."
          exit 1

  cleanup-images:
    name: Clean up old container images
    needs: deploy
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev')
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Set Google Cloud project
        run: gcloud config set project ${{ env.PROJECT_ID }}

      - name: Clean up old images
        continue-on-error: true
        run: |
          echo "Identifying images to clean up in ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }}"

          # Get the image digests for the currently deployed services.
          # The service might not exist, so we default to an empty string.
          prod_image=$(gcloud run services describe sbcwaste-prod --platform managed --region ${{ env.REGION }} --format 'value(template.containers.image)' 2>/dev/null) || prod_image=""
          dev_image=$(gcloud run services describe sbcwaste-dev --platform managed --region ${{ env.REGION }} --format 'value(template.containers.image)' 2>/dev/null) || dev_image=""

          echo "Currently deployed images:"
          echo "Prod: ${prod_image:-'not found'}"
          echo "Dev: ${dev_image:-'not found'}"

          # Get all image versions, sorted from newest to oldest.
          all_images_output=$(gcloud artifacts docker images list ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPO }} --sort-by=~CREATE_TIME --format="get(version)" 2>/dev/null) || all_images_output=""

          # If there are no images in the repo, we can exit successfully.
          if [ -z "$all_images_output" ]; then
            echo "No images found in repository. Nothing to do."
            exit 0
          fi

          # Filter for images of the current service. If grep finds nothing, it exits with 1,
          # so we add `|| true` to prevent the script from exiting.
          all_images=$(echo "$all_images_output" | grep "/${{ env.IMAGE }}@" || true)

          # If there are no images for this service, we can exit successfully.
          if [ -z "$all_images" ]; then
            echo "No images found for this service. Nothing to do."
            exit 0
          fi

          # Build a unique list of images to keep
          images_to_keep_list=()
          [ -n "$prod_image" ] && images_to_keep_list+=("$prod_image")
          [ -n "$dev_image" ] && images_to_keep_list+=("$dev_image")

          # Add the 5 most recent images to the keep list
          images_to_keep_list+=($(echo "$all_images" | head -n 5))

          # Create a unique, sorted list of images to keep
          unique_keep_list=$(printf "%s\n" "${images_to_keep_list[@]}" | sort -u)

          echo "---"
          echo "Images to keep:"
          echo "$unique_keep_list"
          echo "---"

          # Use `grep` to find images that are in all_images but not in unique_keep_list.
          # If grep finds no images to delete, it exits with 1, so we add `|| true`.
          delete_list=$(echo "$all_images" | grep -vFx -f <(echo "$unique_keep_list") || true)

          # Delete the images if the delete list is not empty
          if [ -n "$delete_list" ]; then
            echo "The following images will be deleted:"
            echo "$delete_list"
            echo "$delete_list" | xargs -r gcloud artifacts docker images delete --delete-tags -q
          else
            echo "No images to delete."
          fi